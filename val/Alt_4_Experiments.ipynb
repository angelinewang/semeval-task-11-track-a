{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from tqdm import tqdm\n",
    "from transformers import BertTokenizer, BertModel\n",
    "import spacy\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ad75b0af18244e4b8642b19644bc9362",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:  67%|######6   | 294M/440M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\agupt\\anaconda3\\lib\\site-packages\\huggingface_hub\\file_download.py:140: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\agupt\\.cache\\huggingface\\hub\\models--bert-base-uncased. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    }
   ],
   "source": [
    "# GPU/CPU Device Setup\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Load Data\n",
    "train = pd.read_csv('../public_data/train/track_a/eng.csv')\n",
    "val = pd.read_csv('../public_data/dev/track_a/eng_a.csv')\n",
    "emotions = ['Joy', 'Sadness', 'Surprise', 'Fear', 'Anger']\n",
    "\n",
    "# Initialize BERT Tokenizer & Model\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "bert_model = BertModel.from_pretrained('bert-base-uncased').to(device)\n",
    "nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "We strongly recommend passing in an `attention_mask` since your input_ids may be padded. See https://huggingface.co/docs/transformers/troubleshooting#incorrect-output-when-padding-tokens-arent-masked.\n"
     ]
    }
   ],
   "source": [
    "# Preprocessing Function\n",
    "def pre_process(text):\n",
    "    text = re.sub(r\"[.,;:!?'\\\"“”()]\", \"\", text)  # Remove punctuation\n",
    "    encoded_input = tokenizer(text, return_tensors='pt', truncation=True, padding='max_length', max_length=128)\n",
    "    return encoded_input['input_ids'].squeeze(0).to(device)\n",
    "\n",
    "# Convert Text to BERT Embeddings\n",
    "def get_bert_embeddings(texts):\n",
    "    embeddings = []\n",
    "    for text in texts:\n",
    "        input_ids = pre_process(text).unsqueeze(0)\n",
    "        with torch.no_grad():\n",
    "            outputs = bert_model(input_ids)\n",
    "        embeddings.append(outputs.last_hidden_state[:, 0, :].cpu().numpy())  # Extract [CLS] token\n",
    "    return np.vstack(embeddings)\n",
    "\n",
    "X_train = get_bert_embeddings(train[\"text\"])\n",
    "X_val = get_bert_embeddings(val[\"text\"])\n",
    "\n",
    "# POS Feature Extraction\n",
    "def get_pos_features(texts):\n",
    "    return [[token.pos_ for token in nlp(text)] for text in texts]\n",
    "\n",
    "train_pos_tags = get_pos_features(train[\"text\"])\n",
    "val_pos_tags = get_pos_features(val[\"text\"])\n",
    "\n",
    "# Convert POS Tags to Indices\n",
    "pos_vocab = {pos: idx for idx, pos in enumerate(set(tag for tags in train_pos_tags for tag in tags))}\n",
    "train_pos_indices = [[pos_vocab[tag] for tag in tags] for tags in train_pos_tags]\n",
    "val_pos_indices = [[pos_vocab.get(tag, 0) for tag in tags] for tags in val_pos_tags]\n",
    "\n",
    "# Pad POS Sequences to Fixed Length\n",
    "max_length = max(max(len(seq) for seq in train_pos_indices), max(len(seq) for seq in val_pos_indices))\n",
    "train_pos_indices = [seq + [0] * (max_length - len(seq)) for seq in train_pos_indices]\n",
    "val_pos_indices = [seq + [0] * (max_length - len(seq)) for seq in val_pos_indices]\n",
    "\n",
    "# Convert to PyTorch Tensors\n",
    "train_pos_indices = torch.tensor(train_pos_indices, dtype=torch.long).to(device)\n",
    "val_pos_indices = torch.tensor(val_pos_indices, dtype=torch.long).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trainable POS Embedding Layer\n",
    "class POSEmbedding(nn.Module):\n",
    "    def __init__(self, num_pos_tags, embedding_dim):\n",
    "        super(POSEmbedding, self).__init__()\n",
    "        self.embedding = nn.Embedding(num_embeddings=num_pos_tags, embedding_dim=embedding_dim)\n",
    "\n",
    "    def forward(self, pos_indices):\n",
    "        return self.embedding(pos_indices)\n",
    "\n",
    "pos_embedding_layer = POSEmbedding(len(pos_vocab), embedding_dim=16).to(device)\n",
    "\n",
    "# Model Definition\n",
    "class EmotionClassifier(nn.Module):\n",
    "    def __init__(self, bert_dim=768, pos_dim=16, hidden_dim=128, output_dim=5):\n",
    "        super(EmotionClassifier, self).__init__()\n",
    "        self.fc1 = nn.Linear(bert_dim + pos_dim, hidden_dim)\n",
    "        self.fc2 = nn.Linear(hidden_dim, output_dim)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, bert_embeddings, pos_indices):\n",
    "        pos_embeds = pos_embedding_layer(pos_indices).mean(dim=1)  # Average POS embeddings\n",
    "        combined_features = torch.cat((bert_embeddings, pos_embeds), dim=1)\n",
    "        x = self.relu(self.fc1(combined_features))\n",
    "        return self.fc2(x)\n",
    "\n",
    "# Initialize Model\n",
    "model = EmotionClassifier().to(device)\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-4, weight_decay=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Loop:   0%|          | 1/401 [00:01<08:52,  1.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: Loss: 0.589\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Loop:  25%|██▌       | 101/401 [06:14<23:24,  4.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 100: Loss: 0.438\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Loop:  50%|█████     | 201/401 [13:18<12:42,  3.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 200: Loss: 0.457\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Loop:  75%|███████▌  | 301/401 [20:15<07:44,  4.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 300: Loss: 0.36\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Loop: 100%|██████████| 401/401 [27:02<00:00,  4.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 400: Loss: 0.273\n",
      "Final Loss after 400 epochs: 0.273\n",
      "                        id  Anger  Fear  Joy  Sadness  Surprise\n",
      "0    eng_dev_track_a_00001      0     0    0        1         0\n",
      "1    eng_dev_track_a_00002      0     0    0        1         0\n",
      "2    eng_dev_track_a_00003      0     0    0        1         0\n",
      "3    eng_dev_track_a_00004      0     0    0        1         0\n",
      "4    eng_dev_track_a_00005      0     0    0        1         0\n",
      "..                     ...    ...   ...  ...      ...       ...\n",
      "111  eng_dev_track_a_00112      0     0    0        1         0\n",
      "112  eng_dev_track_a_00113      0     0    0        1         0\n",
      "113  eng_dev_track_a_00114      0     0    0        1         0\n",
      "114  eng_dev_track_a_00115      0     0    0        1         0\n",
      "115  eng_dev_track_a_00116      0     0    0        1         0\n",
      "\n",
      "[116 rows x 6 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "C:\\Users\\agupt\\AppData\\Local\\Temp\\ipykernel_32456\\2285540281.py:41: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(f'./08-02-25/net_epoch_{epoch}.pth'))\n",
      "C:\\Users\\agupt\\AppData\\Local\\Temp\\ipykernel_32456\\2285540281.py:41: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(f'./08-02-25/net_epoch_{epoch}.pth'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                        id  Anger  Fear  Joy  Sadness  Surprise\n",
      "0    eng_dev_track_a_00001      0     0    0        1         0\n",
      "1    eng_dev_track_a_00002      0     0    0        1         0\n",
      "2    eng_dev_track_a_00003      1     0    0        0         0\n",
      "3    eng_dev_track_a_00004      0     1    0        1         0\n",
      "4    eng_dev_track_a_00005      0     0    0        0         0\n",
      "..                     ...    ...   ...  ...      ...       ...\n",
      "111  eng_dev_track_a_00112      0     0    0        1         0\n",
      "112  eng_dev_track_a_00113      0     0    1        0         0\n",
      "113  eng_dev_track_a_00114      0     1    0        1         0\n",
      "114  eng_dev_track_a_00115      0     0    0        1         0\n",
      "115  eng_dev_track_a_00116      0     0    1        1         0\n",
      "\n",
      "[116 rows x 6 columns]\n",
      "                        id  Anger  Fear  Joy  Sadness  Surprise\n",
      "0    eng_dev_track_a_00001      0     0    1        1         0\n",
      "1    eng_dev_track_a_00002      0     0    0        1         0\n",
      "2    eng_dev_track_a_00003      1     0    0        0         0\n",
      "3    eng_dev_track_a_00004      0     1    0        1         0\n",
      "4    eng_dev_track_a_00005      1     0    0        0         0\n",
      "..                     ...    ...   ...  ...      ...       ...\n",
      "111  eng_dev_track_a_00112      0     0    1        1         0\n",
      "112  eng_dev_track_a_00113      0     0    1        1         0\n",
      "113  eng_dev_track_a_00114      0     1    0        1         0\n",
      "114  eng_dev_track_a_00115      0     0    0        1         0\n",
      "115  eng_dev_track_a_00116      0     0    1        1         0\n",
      "\n",
      "[116 rows x 6 columns]\n",
      "                        id  Anger  Fear  Joy  Sadness  Surprise\n",
      "0    eng_dev_track_a_00001      0     0    1        1         0\n",
      "1    eng_dev_track_a_00002      0     0    0        1         0\n",
      "2    eng_dev_track_a_00003      1     0    0        0         0\n",
      "3    eng_dev_track_a_00004      0     1    0        1         0\n",
      "4    eng_dev_track_a_00005      1     0    0        0         0\n",
      "..                     ...    ...   ...  ...      ...       ...\n",
      "111  eng_dev_track_a_00112      0     0    0        1         0\n",
      "112  eng_dev_track_a_00113      0     0    1        1         0\n",
      "113  eng_dev_track_a_00114      0     1    0        1         0\n",
      "114  eng_dev_track_a_00115      0     0    0        1         0\n",
      "115  eng_dev_track_a_00116      0     0    1        1         0\n",
      "\n",
      "[116 rows x 6 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\agupt\\AppData\\Local\\Temp\\ipykernel_32456\\2285540281.py:41: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(f'./08-02-25/net_epoch_{epoch}.pth'))\n",
      "C:\\Users\\agupt\\AppData\\Local\\Temp\\ipykernel_32456\\2285540281.py:41: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(f'./08-02-25/net_epoch_{epoch}.pth'))\n",
      "C:\\Users\\agupt\\AppData\\Local\\Temp\\ipykernel_32456\\2285540281.py:41: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(f'./08-02-25/net_epoch_{epoch}.pth'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                        id  Anger  Fear  Joy  Sadness  Surprise\n",
      "0    eng_dev_track_a_00001      0     0    1        1         0\n",
      "1    eng_dev_track_a_00002      0     0    0        1         0\n",
      "2    eng_dev_track_a_00003      1     0    0        0         0\n",
      "3    eng_dev_track_a_00004      0     1    0        1         0\n",
      "4    eng_dev_track_a_00005      1     0    0        0         0\n",
      "..                     ...    ...   ...  ...      ...       ...\n",
      "111  eng_dev_track_a_00112      0     0    0        1         0\n",
      "112  eng_dev_track_a_00113      0     0    1        1         0\n",
      "113  eng_dev_track_a_00114      0     1    0        1         0\n",
      "114  eng_dev_track_a_00115      0     0    0        0         0\n",
      "115  eng_dev_track_a_00116      0     0    1        1         0\n",
      "\n",
      "[116 rows x 6 columns]\n"
     ]
    }
   ],
   "source": [
    "# Prepare Training Data\n",
    "y_train = torch.tensor(train[emotions].values, dtype=torch.float32).to(device)\n",
    "y_val = torch.tensor(val[emotions].values, dtype=torch.float32).to(device)\n",
    "\n",
    "train_features = torch.tensor(X_train, dtype=torch.float32).to(device)\n",
    "val_features = torch.tensor(X_val, dtype=torch.float32).to(device)\n",
    "\n",
    "dataset = TensorDataset(train_features, train_pos_indices, y_train)\n",
    "data_loader = DataLoader(dataset, batch_size=16, shuffle=True)\n",
    "\n",
    "# Training Loop\n",
    "epochs = 400\n",
    "losses = []\n",
    "\n",
    "for epoch in tqdm(range(epochs + 1), desc=\"Training Loop\"):\n",
    "    model.train()\n",
    "    for features, pos_indices, labels in data_loader:\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(features, pos_indices)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    if epoch % 100 == 0:\n",
    "        print(f\"Epoch {epoch}: Loss: {round(loss.item(), 3)}\")\n",
    "        torch.save(model.state_dict(), f'./08-02-25/net_epoch_{epoch}.pth')\n",
    "        losses.append(round(loss.item(), 3))\n",
    "\n",
    "print(f\"Final Loss after {epochs} epochs: {losses[-1]}\")\n",
    "\n",
    "# Prediction Function\n",
    "def get_predictions(X_val, pos_indices, model, threshold=0.5):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        yhat = torch.sigmoid(model(X_val, pos_indices)).cpu().numpy()\n",
    "    return yhat > threshold\n",
    "\n",
    "# Generate Predictions for Multiple Epochs\n",
    "for i in range(5):\n",
    "    epoch = i * 100\n",
    "    model.load_state_dict(torch.load(f'./08-02-25/net_epoch_{epoch}.pth'))\n",
    "    y_pred = get_predictions(val_features, val_pos_indices, model, 0.45)\n",
    "\n",
    "    val_data_with_pred = pd.DataFrame(y_pred, columns=['Anger', 'Fear', 'Joy', 'Sadness', 'Surprise'])\n",
    "    val_data_with_pred = val_data_with_pred.astype(int)\n",
    "    val_data_with_pred['id'] = val['id']\n",
    "    val_data_with_pred = val_data_with_pred[['id', 'Anger', 'Fear', 'Joy', 'Sadness', 'Surprise']]\n",
    "\n",
    "    formatted_time = datetime.datetime.now().strftime('%Y-%m-%d_%H_%M_%S')\n",
    "    val_data_with_pred.to_csv(f'../results/alt_exp_4/alt_exp_4_epoch_{epoch}_pred_eng_a_{formatted_time}.csv', index=False)\n",
    "\n",
    "    print(val_data_with_pred)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
