{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Loop:   0%|          | 1/1000 [00:02<47:56,  2.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: Loss: 0.928\n",
      "Saved epoch 0 weights to './21-12-24(1)/net_epoch_0.pth'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Loop:  10%|█         | 101/1000 [03:09<30:47,  2.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 100: Loss: 0.013\n",
      "Saved epoch 100 weights to './21-12-24(1)/net_epoch_100.pth'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Loop:  20%|██        | 201/1000 [06:25<23:04,  1.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 200: Loss: 0.005\n",
      "Saved epoch 200 weights to './21-12-24(1)/net_epoch_200.pth'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Loop:  30%|███       | 301/1000 [09:20<14:28,  1.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 300: Loss: 0.003\n",
      "Saved epoch 300 weights to './21-12-24(1)/net_epoch_300.pth'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Loop:  40%|████      | 401/1000 [12:22<18:49,  1.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 400: Loss: 0.001\n",
      "Saved epoch 400 weights to './21-12-24(1)/net_epoch_400.pth'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Loop:  50%|█████     | 501/1000 [15:11<16:10,  1.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 500: Loss: 0.0\n",
      "Saved epoch 500 weights to './21-12-24(1)/net_epoch_500.pth'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Loop:  60%|██████    | 601/1000 [18:31<13:45,  2.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 600: Loss: 0.003\n",
      "Saved epoch 600 weights to './21-12-24(1)/net_epoch_600.pth'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Loop:  70%|███████   | 701/1000 [21:16<05:42,  1.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 700: Loss: 0.006\n",
      "Saved epoch 700 weights to './21-12-24(1)/net_epoch_700.pth'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Loop:  80%|████████  | 801/1000 [23:10<03:33,  1.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 800: Loss: 0.001\n",
      "Saved epoch 800 weights to './21-12-24(1)/net_epoch_800.pth'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Loop:  90%|█████████ | 901/1000 [25:09<01:38,  1.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 900: Loss: 0.002\n",
      "Saved epoch 900 weights to './21-12-24(1)/net_epoch_900.pth'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Loop: 100%|██████████| 1000/1000 [26:58<00:00,  1.62s/it]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from tqdm import tqdm\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer, WordNetLemmatizer\n",
    "from transformers import BertTokenizer\n",
    "from nltk.util import ngrams\n",
    "import spacy\n",
    "import re\n",
    "\n",
    "# Load Data\n",
    "train = pd.read_csv('../public_data/train/track_a/eng.csv')\n",
    "val = pd.read_csv('../public_data/dev/track_a/eng_a.csv')\n",
    "emotions = ['Joy', 'Sadness', 'Surprise', 'Fear', 'Anger']\n",
    "\n",
    "# Preprocessing Config\n",
    "config = {'sep_pn': True, 'rm_pn': False, 'apply_lemmatization': True, 'apply_stemming': True, 'add_bigrams': True, 'rm_sw': False}\n",
    "\n",
    "# Preprocessing Functions\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "def pre_process(text, config):\n",
    "    def separate_punctuation(text):\n",
    "        text = re.sub(r\"(\\w)([.,;:!?'\\\"”\\)])\", r\"\\1 \\2\", text)\n",
    "        text = re.sub(r\"([.,;:!?'\\\"“\\(\\)])(\\w)\", r\"\\1 \\2\", text)\n",
    "        return text\n",
    "\n",
    "    def remove_punctuation(text):\n",
    "        text = re.sub(r\"[.,;:!?'\\\"“”\\(\\)]\", \"\", text)\n",
    "        return text\n",
    "\n",
    "    def tokenize_text(text):\n",
    "        encoded_input = tokenizer(text, return_tensors='pt', add_special_tokens=True)\n",
    "        tokens = tokenizer.convert_ids_to_tokens(encoded_input['input_ids'][0])\n",
    "        return tokens\n",
    "\n",
    "    def apply_stemming(tokens):\n",
    "        stemmer = PorterStemmer()\n",
    "        return [stemmer.stem(token) for token in tokens]\n",
    "\n",
    "    def apply_lemmatization(tokens):\n",
    "        lemmatizer = WordNetLemmatizer()\n",
    "        return [lemmatizer.lemmatize(token) for token in tokens]\n",
    "\n",
    "    def generate_ngrams_from_tokens(tokens, n):\n",
    "        return [\" \".join(gram) for gram in ngrams(tokens, n)]\n",
    "\n",
    "    # Apply config options\n",
    "    if config['sep_pn'] and not config['rm_pn']:\n",
    "        text = separate_punctuation(text)\n",
    "    if config['rm_pn'] and not config['sep_pn']:\n",
    "        text = remove_punctuation(text)\n",
    "\n",
    "    tokens = tokenize_text(text)\n",
    "    if config['apply_stemming']:\n",
    "        tokens = apply_stemming(tokens)\n",
    "    if config['apply_lemmatization']:\n",
    "        tokens = apply_lemmatization(tokens)\n",
    "    if config['add_bigrams']:\n",
    "        tokens += generate_ngrams_from_tokens(tokens, 2)\n",
    "    if config['rm_sw']:\n",
    "        stop_words = set(stopwords.words('english'))\n",
    "        tokens = [word for word in tokens if word.lower() not in stop_words]\n",
    "\n",
    "    return \" \".join(tokens)\n",
    "\n",
    "# Preprocess and Extract Features\n",
    "vectorizer = CountVectorizer()\n",
    "\n",
    "train_text = [pre_process(text, config) for text in train[\"text\"]]\n",
    "val_text = [pre_process(text, config) for text in val[\"text\"]]\n",
    "\n",
    "X_train = vectorizer.fit_transform(train_text).toarray()\n",
    "X_val = vectorizer.transform(val_text).toarray()\n",
    "\n",
    "# POS Tagging\n",
    "def extract_pos_tags(texts):\n",
    "    return [[token.pos_ for token in nlp(text)] for text in texts]\n",
    "\n",
    "train_pos_tags = extract_pos_tags(train[\"text\"])\n",
    "val_pos_tags = extract_pos_tags(val[\"text\"])\n",
    "\n",
    "# POS Encoding\n",
    "max_length = max(max(len(tags) for tags in train_pos_tags), max(len(tags) for tags in val_pos_tags))\n",
    "train_pos_tags = [tags + ['PAD'] * (max_length - len(tags)) for tags in train_pos_tags]\n",
    "val_pos_tags = [tags + ['PAD'] * (max_length - len(tags)) for tags in val_pos_tags]\n",
    "\n",
    "encoder = OneHotEncoder(sparse_output=False, handle_unknown=\"ignore\")\n",
    "train_pos_encoded = encoder.fit_transform(train_pos_tags)\n",
    "val_pos_encoded = encoder.transform(val_pos_tags)\n",
    "\n",
    "# Combine Features\n",
    "combined_features = np.concatenate((X_train, train_pos_encoded), axis=1)\n",
    "validation_combined_features = np.concatenate((X_val, val_pos_encoded), axis=1)\n",
    "\n",
    "# Logistic Regression for Enhanced Features\n",
    "y_train = train[emotions].values\n",
    "lr = LogisticRegression(max_iter=1000)\n",
    "lr.fit(combined_features, np.argmax(y_train, axis=1))\n",
    "\n",
    "lr_features = lr.predict_proba(combined_features)\n",
    "val_lr_features = lr.predict_proba(validation_combined_features)\n",
    "\n",
    "final_train_features = np.concatenate((combined_features, lr_features), axis=1)\n",
    "final_val_features = np.concatenate((validation_combined_features, val_lr_features), axis=1)\n",
    "\n",
    "# Neural Network\n",
    "model = nn.Sequential(\n",
    "    nn.Linear(final_train_features.shape[1], 128),\n",
    "    nn.BatchNorm1d(128),\n",
    "    nn.ReLU(),\n",
    "    nn.Dropout(0.4),\n",
    "    nn.Linear(128, 64),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(64, y_train.shape[1])\n",
    ")\n",
    "\n",
    "# DataLoader\n",
    "features_tensor = torch.tensor(final_train_features, dtype=torch.float32)\n",
    "labels_tensor = torch.tensor(y_train, dtype=torch.float32)\n",
    "dataset = TensorDataset(features_tensor, labels_tensor)\n",
    "data_loader = DataLoader(dataset, batch_size=16, shuffle=True)\n",
    "\n",
    "weights = y_train.sum(axis=0)/y_train.sum()\n",
    "weights = max(weights)/weights\n",
    "\n",
    "# Loss and Optimizer\n",
    "# criterion = nn.BCEWithLogitsLoss()\n",
    "# optimizer = optim.Adam(model.parameters(), lr=1e-4, weight_decay=1e-4)\n",
    "\n",
    "criterion = nn.BCEWithLogitsLoss(pos_weight=torch.Tensor(weights)) # <-- weights assigned to optimiser\n",
    "optimizer = optim.SGD(model.parameters(), lr=1e-2, weight_decay=1e-4)\n",
    "\n",
    "# Training Loop\n",
    "losses = []\n",
    "for epoch in tqdm(range(1000), desc=\"Training Loop\"):\n",
    "    for features, labels in data_loader:\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(features)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    # if epoch % 100 == 0:\n",
    "    #     print(f\"Epoch {epoch}: Loss: {round(loss.item(), 3)}\")\n",
    "    # losses.append(loss.item())\n",
    "    if epoch % 100 == 0:\n",
    "        print(f'Epoch {epoch}: Loss: {round(loss.item(),3)}')\n",
    "        # Save the trained model's weights for future use.\n",
    "        torch.save(model.state_dict(), f'./21-12-24(1)/net_epoch_{epoch}.pth')\n",
    "        print(f\"Saved epoch {epoch} weights to './21-12-24(1)/net_epoch_{epoch}.pth'\")\n",
    "        losses.append(round(loss.item(),3))\n",
    "    if epoch == 1000:\n",
    "        print(f'Epoch {epoch}: Loss: {round(loss.item(),3)}')\n",
    "        # Save the trained model's weights for future use.\n",
    "        torch.save(model.state_dict(), f'./21-12-24(1)/net_epoch_{epoch}.pth')\n",
    "        print(f\"Saved epoch {epoch} weights to './21-12-24(1)/net_epoch_{epoch}.pth'\")\n",
    "        losses.append(round(loss.item(),3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Loss after 1000 epochs: 0.002\n"
     ]
    }
   ],
   "source": [
    "# Final Loss\n",
    "print(f\"Final Loss after 1000 epochs: {losses[-1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[0.00000000e+00, 0.00000000e+00, 0.00000000e+00, ...,\n",
       "         3.37153346e-03, 2.03434673e-04, 1.06744582e-04],\n",
       "        [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, ...,\n",
       "         6.01568564e-02, 3.33009357e-01, 2.31915457e-04],\n",
       "        [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, ...,\n",
       "         2.26728178e-02, 9.27401246e-03, 1.08520154e-03],\n",
       "        ...,\n",
       "        [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, ...,\n",
       "         4.98633799e-03, 3.81255445e-01, 1.96406709e-02],\n",
       "        [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, ...,\n",
       "         1.88115472e-01, 4.96022926e-02, 7.41382697e-03],\n",
       "        [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, ...,\n",
       "         3.32888115e-01, 2.58945858e-03, 1.28381599e-02]]),\n",
       " [0.928, 0.013, 0.005, 0.003, 0.001, 0.0, 0.003, 0.006, 0.001, 0.002])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_val_features, losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x23132adcdf0>]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "eps = [100*i for i in range(0,10)]\n",
    "\n",
    "plt.plot(eps, losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_predictions(X_val, model, threshold=0.5):\n",
    "    sig = nn.Sigmoid() \n",
    "    yhat = sig(model(X_val)).detach().numpy()\n",
    "    y_pred = yhat > threshold\n",
    "    \n",
    "    return y_pred\n",
    "\n",
    "# y_pred = get_predictions(torch.Tensor(final_val_features), model, 0.45)\n",
    "# # print(y_pred)\n",
    "\n",
    "# # Create a DataFrame to save to CSV\n",
    "# val_data_with_pred = pd.DataFrame(y_pred, columns=['Anger', 'Fear', 'Joy', 'Sadness', 'Surprise'])  # Adjust column names as per your features\n",
    "# # val_data_with_pred['True_Label'] = y_test\n",
    "# # val_data_with_pred['Predictions'] = dummy_predictions\n",
    "\n",
    "# val_data_with_pred = val_data_with_pred.astype(int)\n",
    "\n",
    "# val_data_with_pred['id'] = val['id']\n",
    "\n",
    "# val_data_with_pred = val_data_with_pred[['id', 'Anger', 'Fear', 'Joy', 'Sadness', 'Surprise']]\n",
    "\n",
    "# # Save to CSV\n",
    "# current_time = datetime.datetime.now()\n",
    "# formatted_time = current_time.strftime('%Y-%m-%d_%H_%M_%S')\n",
    "\n",
    "# val_data_with_pred.to_csv(f'../results/pred_eng_a_{formatted_time}.csv', index=False)\n",
    "\n",
    "# print(val_data_with_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                        id  Anger  Fear  Joy  Sadness  Surprise\n",
      "0    eng_dev_track_a_00001      1     1    0        1         0\n",
      "1    eng_dev_track_a_00002      1     1    1        1         0\n",
      "2    eng_dev_track_a_00003      1     1    0        1         0\n",
      "3    eng_dev_track_a_00004      1     0    0        1         0\n",
      "4    eng_dev_track_a_00005      1     1    0        0         0\n",
      "..                     ...    ...   ...  ...      ...       ...\n",
      "111  eng_dev_track_a_00112      1     1    1        1         0\n",
      "112  eng_dev_track_a_00113      1     1    1        1         0\n",
      "113  eng_dev_track_a_00114      1     1    0        1         0\n",
      "114  eng_dev_track_a_00115      1     1    1        1         0\n",
      "115  eng_dev_track_a_00116      1     1    1        1         0\n",
      "\n",
      "[116 rows x 6 columns]\n",
      "                        id  Anger  Fear  Joy  Sadness  Surprise\n",
      "0    eng_dev_track_a_00001      0     1    0        0         0\n",
      "1    eng_dev_track_a_00002      0     1    0        1         0\n",
      "2    eng_dev_track_a_00003      1     0    1        0         0\n",
      "3    eng_dev_track_a_00004      1     0    0        1         0\n",
      "4    eng_dev_track_a_00005      0     0    0        0         0\n",
      "..                     ...    ...   ...  ...      ...       ...\n",
      "111  eng_dev_track_a_00112      0     0    0        1         0\n",
      "112  eng_dev_track_a_00113      0     0    1        1         0\n",
      "113  eng_dev_track_a_00114      0     0    0        1         0\n",
      "114  eng_dev_track_a_00115      0     1    0        0         0\n",
      "115  eng_dev_track_a_00116      0     0    1        0         0\n",
      "\n",
      "[116 rows x 6 columns]\n",
      "                        id  Anger  Fear  Joy  Sadness  Surprise\n",
      "0    eng_dev_track_a_00001      0     0    0        0         0\n",
      "1    eng_dev_track_a_00002      0     1    0        1         0\n",
      "2    eng_dev_track_a_00003      1     0    0        0         0\n",
      "3    eng_dev_track_a_00004      0     0    0        1         0\n",
      "4    eng_dev_track_a_00005      0     0    0        0         0\n",
      "..                     ...    ...   ...  ...      ...       ...\n",
      "111  eng_dev_track_a_00112      0     0    0        1         1\n",
      "112  eng_dev_track_a_00113      0     0    1        1         0\n",
      "113  eng_dev_track_a_00114      0     0    0        1         0\n",
      "114  eng_dev_track_a_00115      0     1    0        0         0\n",
      "115  eng_dev_track_a_00116      0     0    1        1         0\n",
      "\n",
      "[116 rows x 6 columns]\n",
      "                        id  Anger  Fear  Joy  Sadness  Surprise\n",
      "0    eng_dev_track_a_00001      0     1    1        1         0\n",
      "1    eng_dev_track_a_00002      0     1    0        1         0\n",
      "2    eng_dev_track_a_00003      1     0    1        0         0\n",
      "3    eng_dev_track_a_00004      1     0    0        1         0\n",
      "4    eng_dev_track_a_00005      0     0    0        0         0\n",
      "..                     ...    ...   ...  ...      ...       ...\n",
      "111  eng_dev_track_a_00112      0     0    0        1         0\n",
      "112  eng_dev_track_a_00113      0     0    1        1         0\n",
      "113  eng_dev_track_a_00114      0     0    0        1         0\n",
      "114  eng_dev_track_a_00115      0     1    0        0         0\n",
      "115  eng_dev_track_a_00116      0     0    1        0         0\n",
      "\n",
      "[116 rows x 6 columns]\n",
      "                        id  Anger  Fear  Joy  Sadness  Surprise\n",
      "0    eng_dev_track_a_00001      0     1    0        0         0\n",
      "1    eng_dev_track_a_00002      0     0    0        1         0\n",
      "2    eng_dev_track_a_00003      1     0    1        0         0\n",
      "3    eng_dev_track_a_00004      1     0    0        0         0\n",
      "4    eng_dev_track_a_00005      0     0    0        0         0\n",
      "..                     ...    ...   ...  ...      ...       ...\n",
      "111  eng_dev_track_a_00112      0     0    0        1         0\n",
      "112  eng_dev_track_a_00113      0     0    1        1         0\n",
      "113  eng_dev_track_a_00114      0     0    0        1         0\n",
      "114  eng_dev_track_a_00115      0     1    0        0         0\n",
      "115  eng_dev_track_a_00116      0     0    1        0         0\n",
      "\n",
      "[116 rows x 6 columns]\n",
      "                        id  Anger  Fear  Joy  Sadness  Surprise\n",
      "0    eng_dev_track_a_00001      1     0    0        0         0\n",
      "1    eng_dev_track_a_00002      0     1    0        1         0\n",
      "2    eng_dev_track_a_00003      1     0    0        0         0\n",
      "3    eng_dev_track_a_00004      1     0    0        0         0\n",
      "4    eng_dev_track_a_00005      0     0    0        0         0\n",
      "..                     ...    ...   ...  ...      ...       ...\n",
      "111  eng_dev_track_a_00112      0     0    0        1         0\n",
      "112  eng_dev_track_a_00113      0     0    1        1         0\n",
      "113  eng_dev_track_a_00114      0     0    0        1         0\n",
      "114  eng_dev_track_a_00115      0     1    0        0         0\n",
      "115  eng_dev_track_a_00116      0     0    1        0         0\n",
      "\n",
      "[116 rows x 6 columns]\n",
      "                        id  Anger  Fear  Joy  Sadness  Surprise\n",
      "0    eng_dev_track_a_00001      0     0    0        0         0\n",
      "1    eng_dev_track_a_00002      0     1    0        1         0\n",
      "2    eng_dev_track_a_00003      1     0    0        0         0\n",
      "3    eng_dev_track_a_00004      1     0    0        0         0\n",
      "4    eng_dev_track_a_00005      0     0    0        0         0\n",
      "..                     ...    ...   ...  ...      ...       ...\n",
      "111  eng_dev_track_a_00112      0     0    0        1         0\n",
      "112  eng_dev_track_a_00113      0     0    1        1         0\n",
      "113  eng_dev_track_a_00114      0     0    0        1         0\n",
      "114  eng_dev_track_a_00115      0     1    0        0         0\n",
      "115  eng_dev_track_a_00116      0     1    1        1         0\n",
      "\n",
      "[116 rows x 6 columns]\n",
      "                        id  Anger  Fear  Joy  Sadness  Surprise\n",
      "0    eng_dev_track_a_00001      1     1    0        0         0\n",
      "1    eng_dev_track_a_00002      0     0    0        1         0\n",
      "2    eng_dev_track_a_00003      1     0    0        0         0\n",
      "3    eng_dev_track_a_00004      1     0    0        0         0\n",
      "4    eng_dev_track_a_00005      0     0    0        0         1\n",
      "..                     ...    ...   ...  ...      ...       ...\n",
      "111  eng_dev_track_a_00112      0     0    0        1         1\n",
      "112  eng_dev_track_a_00113      0     0    1        1         0\n",
      "113  eng_dev_track_a_00114      0     0    0        1         0\n",
      "114  eng_dev_track_a_00115      0     1    0        0         0\n",
      "115  eng_dev_track_a_00116      0     0    1        0         0\n",
      "\n",
      "[116 rows x 6 columns]\n",
      "                        id  Anger  Fear  Joy  Sadness  Surprise\n",
      "0    eng_dev_track_a_00001      0     1    0        0         0\n",
      "1    eng_dev_track_a_00002      0     1    0        1         0\n",
      "2    eng_dev_track_a_00003      1     0    0        0         0\n",
      "3    eng_dev_track_a_00004      1     0    0        1         0\n",
      "4    eng_dev_track_a_00005      0     0    0        0         0\n",
      "..                     ...    ...   ...  ...      ...       ...\n",
      "111  eng_dev_track_a_00112      0     0    0        1         0\n",
      "112  eng_dev_track_a_00113      0     0    1        1         0\n",
      "113  eng_dev_track_a_00114      0     0    0        1         0\n",
      "114  eng_dev_track_a_00115      0     1    0        0         0\n",
      "115  eng_dev_track_a_00116      0     0    1        1         0\n",
      "\n",
      "[116 rows x 6 columns]\n",
      "                        id  Anger  Fear  Joy  Sadness  Surprise\n",
      "0    eng_dev_track_a_00001      0     1    0        0         0\n",
      "1    eng_dev_track_a_00002      0     0    0        1         0\n",
      "2    eng_dev_track_a_00003      1     0    0        0         0\n",
      "3    eng_dev_track_a_00004      1     0    0        0         0\n",
      "4    eng_dev_track_a_00005      0     0    0        0         0\n",
      "..                     ...    ...   ...  ...      ...       ...\n",
      "111  eng_dev_track_a_00112      0     0    0        1         0\n",
      "112  eng_dev_track_a_00113      0     0    1        1         0\n",
      "113  eng_dev_track_a_00114      0     0    0        1         0\n",
      "114  eng_dev_track_a_00115      0     1    0        0         0\n",
      "115  eng_dev_track_a_00116      0     0    1        1         0\n",
      "\n",
      "[116 rows x 6 columns]\n"
     ]
    }
   ],
   "source": [
    "# DO 10 different prediction files with epochs 100, 200, 300, 400, 500, 600, 700, 800, 900 and 1000 Model parameters\n",
    "\n",
    "# Get 10 differen prediction files\n",
    "\n",
    "for i in range(10):\n",
    "    epoch = i*100\n",
    "    model.load_state_dict(torch.load(f'./21-12-24(1)/net_epoch_{epoch}.pth', weights_only=True))\n",
    "    y_pred = get_predictions(torch.Tensor(final_val_features), model, 0.45)\n",
    "    # print(y_pred)\n",
    "\n",
    "    # Create a DataFrame to save to CSV\n",
    "    val_data_with_pred = pd.DataFrame(y_pred, columns=['Anger', 'Fear', 'Joy', 'Sadness', 'Surprise'])  # Adjust column names as per your features\n",
    "    # val_data_with_pred['True_Label'] = y_test\n",
    "    # val_data_with_pred['Predictions'] = dummy_predictions\n",
    "\n",
    "    val_data_with_pred = val_data_with_pred.astype(int)\n",
    "\n",
    "    val_data_with_pred['id'] = val['id']\n",
    "\n",
    "    val_data_with_pred = val_data_with_pred[['id', 'Anger', 'Fear', 'Joy', 'Sadness', 'Surprise']]\n",
    "\n",
    "    # Save to CSV\n",
    "    current_time = datetime.datetime.now()\n",
    "    formatted_time = current_time.strftime('%Y-%m-%d_%H_%M_%S')\n",
    "\n",
    "    val_data_with_pred.to_csv(f'../results/alt4_2/alt4_epoch_{epoch}_pred_eng_a_{formatted_time}.csv', index=False)\n",
    "\n",
    "    print(val_data_with_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. For Submission 5 files:\n",
    "\n",
    "    Your results for eng track A are:\n",
    "\n",
    "    Multi-label accuracy (Jaccard score): 0.26063218390804593\n",
    "\n",
    "    Micro F1 score: 0.41758241758241754\n",
    "\n",
    "    Macro F1 score: 0.36549662349391404\n",
    "\n",
    "2. For Submission 6 files:\n",
    "\n",
    "    Your results for eng track A are:\n",
    "\n",
    "    Multi-label accuracy (Jaccard score): 0.26206896551724135\n",
    "\n",
    "    Micro F1 score: 0.42659279778393355\n",
    "\n",
    "    Macro F1 score: 0.36911780259117266"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Epoch | Jaccard Index | Micro F1 | Macro F1 |\n",
    "| ----- | ------------- | -------- | -------- |\n",
    "| 0     |               |          |          |\n",
    "| 100   |               |          |          |\n",
    "| 200   |               |          |          |\n",
    "| 300   |               |          |          |\n",
    "| 400   |               |          |          |\n",
    "| 500   |               |          |          |\n",
    "| 600   |               |          |          |\n",
    "| 700   |               |          |          |\n",
    "| 800   |               |          |          |\n",
    "| 900   |               |          |          |\n",
    "| 1000  |               |          |          |"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
