{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gDwpEarSTqyY"
      },
      "outputs": [],
      "source": [
        "import datetime\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "from tqdm import tqdm\n",
        "from transformers import BertTokenizer, BertModel\n",
        "import spacy\n",
        "import re\n",
        "from sklearn.metrics import precision_recall_fscore_support"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gL1xDIAXVKN9"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Fg6m75ejVN2E"
      },
      "outputs": [],
      "source": [
        "cd drive/MyDrive/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-82BE0UJVPyE"
      },
      "outputs": [],
      "source": [
        "cd CodaBench_Sem_Eval"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mYLyQXHpVRs2"
      },
      "outputs": [],
      "source": [
        " cd val"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y87ogdxiTwaw"
      },
      "outputs": [],
      "source": [
        "# GPU/CPU Device Setup\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "# Load Data\n",
        "train = pd.read_csv('../public_data_test/track_a/train/eng.csv')\n",
        "val = pd.read_csv('../public_data_test/track_a/dev/eng.csv')\n",
        "test = pd.read_csv('../public_data_test/track_a/test/eng.csv')\n",
        "emotions = [\"anger\", \"fear\", \"joy\", \"sadness\", \"surprise\"]\n",
        "\n",
        "# Initialize BERT Tokenizer & Model\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "bert_model = BertModel.from_pretrained('bert-base-uncased').to(device)\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "\n",
        "# Define POS Embeddings\n",
        "POS_VOCAB = {pos: idx for idx, pos in enumerate(nlp.pipe_labels[\"tagger\"])}\n",
        "pos_embedding_layer = nn.Embedding(len(POS_VOCAB), 16).to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d_QRwmBJT1Iw"
      },
      "outputs": [],
      "source": [
        "# Adversarial Training Function (FGSM)\n",
        "def fgsm_attack(inputs, epsilon, gradients):\n",
        "    sign_grad = gradients.sign()\n",
        "    perturbed_inputs = inputs + epsilon * sign_grad\n",
        "    return torch.clamp(perturbed_inputs, 0, 1)\n",
        "\n",
        "# Define Model (BERT + POS Embeddings)\n",
        "class EmotionClassifier(nn.Module):\n",
        "    def __init__(self, num_classes=5):\n",
        "        super(EmotionClassifier, self).__init__()\n",
        "        self.bert = bert_model\n",
        "        self.dropout = nn.Dropout(0.3)\n",
        "        self.fc = nn.Linear(768 + 16, num_classes)  # BERT + POS Embedding\n",
        "        self.softmax = nn.Softmax(dim=1)\n",
        "\n",
        "    def forward(self, input_ids, attention_mask, pos_tags):\n",
        "        bert_output = self.bert(input_ids=input_ids, attention_mask=attention_mask).last_hidden_state[:, 0, :]  # Shape: (batch_size, 768)\n",
        "        pos_embeds = pos_embedding_layer(pos_tags).mean(dim=1)  # Aggregate across sequence length, Shape: (batch_size, 16)\n",
        "\n",
        "        combined = torch.cat((bert_output, pos_embeds), dim=1)  # Now both tensors are (batch_size, 768 + 16)\n",
        "        output = self.fc(self.dropout(combined))\n",
        "        return self.softmax(output)\n",
        "\n",
        "# Initialize Model\n",
        "model = EmotionClassifier().to(device)\n",
        "\n",
        "# Optimizer & Learning Rate Scheduling\n",
        "optimizer = optim.AdamW(model.parameters(), lr=2e-5, weight_decay=1e-2)\n",
        "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=2)\n",
        "\n",
        "# Early Stopping Criteria\n",
        "class EarlyStopping:\n",
        "    def __init__(self, patience=3):\n",
        "        self.patience = patience\n",
        "        self.counter = 0\n",
        "        self.best_loss = float('inf')\n",
        "\n",
        "    def check(self, val_loss):\n",
        "        if val_loss < self.best_loss:\n",
        "            self.best_loss = val_loss\n",
        "            self.counter = 0\n",
        "        else:\n",
        "            self.counter += 1\n",
        "        return self.counter >= self.patience\n",
        "\n",
        "early_stopping = EarlyStopping()\n",
        "\n",
        "# Dynamic Thresholding Function\n",
        "def dynamic_thresholding(preds, labels, thresholds):\n",
        "    final_preds = torch.zeros_like(preds)\n",
        "    for i, threshold in enumerate(thresholds):\n",
        "        final_preds[:, i] = (preds[:, i] > threshold).float()\n",
        "    return final_preds\n",
        "\n",
        "# Tokenization & POS Tagging\n",
        "def preprocess(texts):\n",
        "    input_ids, attention_masks, pos_tags = [], [], []\n",
        "\n",
        "    for text in texts:\n",
        "        encoded = tokenizer(text, padding='max_length', truncation=True, return_tensors='pt', max_length=32)\n",
        "        pos_sequence = [POS_VOCAB.get(token.pos_, 0) for token in nlp(text)]\n",
        "\n",
        "        # Ensure POS sequence matches max_length (BERT tokenization)\n",
        "        if len(pos_sequence) < 32:\n",
        "            pos_sequence += [0] * (32 - len(pos_sequence))  # Pad with zeros\n",
        "        else:\n",
        "            pos_sequence = pos_sequence[:32]  # Truncate if too long\n",
        "\n",
        "        input_ids.append(encoded['input_ids'])\n",
        "        attention_masks.append(encoded['attention_mask'])\n",
        "        pos_tags.append(torch.tensor(pos_sequence, dtype=torch.long))  # Ensure correct dtype\n",
        "\n",
        "    return torch.cat(input_ids), torch.cat(attention_masks), torch.stack(pos_tags)\n",
        "\n",
        "\n",
        "# Prepare Data\n",
        "train_texts, val_texts = train['text'].tolist(), val['text'].tolist()\n",
        "train_labels, val_labels = torch.tensor(train[emotions].values), torch.tensor(val[emotions].values)\n",
        "train_inputs, train_masks, train_pos = preprocess(train_texts)\n",
        "val_inputs, val_masks, val_pos = preprocess(val_texts)\n",
        "\n",
        "# Dataloaders\n",
        "train_data = TensorDataset(train_inputs, train_masks, train_pos, train_labels)\n",
        "val_data = TensorDataset(val_inputs, val_masks, val_pos, val_labels)\n",
        "train_loader = DataLoader(train_data, batch_size=16, shuffle=True)\n",
        "val_loader = DataLoader(val_data, batch_size=16, shuffle=False)\n",
        "\n",
        "# Training Loop\n",
        "best_thresholds = [0.5] * len(emotions)\n",
        "for epoch in range(10):\n",
        "    model.train()\n",
        "    for batch in train_loader:\n",
        "        input_ids, attention_mask, pos_tags, labels = [x.to(device) for x in batch]\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(input_ids, attention_mask, pos_tags)\n",
        "        loss = nn.BCELoss()(outputs, labels.float())\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    # Validation Step\n",
        "    model.eval()\n",
        "    val_loss, all_preds, all_labels = 0, [], []\n",
        "    with torch.no_grad():\n",
        "        for batch in val_loader:\n",
        "            input_ids, attention_mask, pos_tags, labels = [x.to(device) for x in batch]\n",
        "            outputs = model(input_ids, attention_mask, pos_tags)\n",
        "            loss = nn.BCELoss()(outputs, labels.float())\n",
        "            val_loss += loss.item()\n",
        "            all_preds.append(outputs.cpu())\n",
        "            all_labels.append(labels.cpu())\n",
        "\n",
        "    scheduler.step(val_loss)\n",
        "\n",
        "    # Dynamic Thresholding Calculation\n",
        "    all_preds, all_labels = torch.cat(all_preds), torch.cat(all_labels)\n",
        "    best_thresholds = [0.5] * len(emotions)  # Placeholder for future tuning\n",
        "    final_preds = dynamic_thresholding(all_preds, all_labels, best_thresholds)\n",
        "\n",
        "    # Compute Metrics\n",
        "    precision, recall, f1, _ = precision_recall_fscore_support(all_labels, final_preds, average='macro')\n",
        "    print(f\"Epoch {epoch+1}: Val Loss {val_loss:.4f}, F1 Score {f1:.4f}\")\n",
        "\n",
        "    if early_stopping.check(val_loss):\n",
        "        print(\"Early stopping triggered.\")\n",
        "        break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ycAm4iBhYuji"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import classification_report"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qBIng05jXWE-"
      },
      "outputs": [],
      "source": [
        "y_pred = final_preds.numpy()\n",
        "y_test = all_labels.numpy()\n",
        "\n",
        "# Generate and print the classification report\n",
        "print(\"\\nFinal Validation Performance with Best Thresholds:\")\n",
        "print(classification_report(\n",
        "    y_test,\n",
        "    y_pred,\n",
        "    target_names=emotions\n",
        "))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "03i6H6pcYtKf"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "private_outputs": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
