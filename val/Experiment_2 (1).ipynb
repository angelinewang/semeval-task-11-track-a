{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "u0hDXAP3nGcN"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nlpaug in /opt/conda/lib/python3.11/site-packages (1.1.11)\n",
      "Requirement already satisfied: numpy>=1.16.2 in /opt/conda/lib/python3.11/site-packages (from nlpaug) (2.0.2)\n",
      "Requirement already satisfied: pandas>=1.2.0 in /opt/conda/lib/python3.11/site-packages (from nlpaug) (2.2.2)\n",
      "Requirement already satisfied: requests>=2.22.0 in /opt/conda/lib/python3.11/site-packages (from nlpaug) (2.32.3)\n",
      "Requirement already satisfied: gdown>=4.0.0 in /opt/conda/lib/python3.11/site-packages (from nlpaug) (5.2.0)\n",
      "Requirement already satisfied: beautifulsoup4 in /opt/conda/lib/python3.11/site-packages (from gdown>=4.0.0->nlpaug) (4.12.3)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.11/site-packages (from gdown>=4.0.0->nlpaug) (3.15.4)\n",
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.11/site-packages (from gdown>=4.0.0->nlpaug) (4.66.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.11/site-packages (from pandas>=1.2.0->nlpaug) (2.9.0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.11/site-packages (from pandas>=1.2.0->nlpaug) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.11/site-packages (from pandas>=1.2.0->nlpaug) (2024.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.11/site-packages (from requests>=2.22.0->nlpaug) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.11/site-packages (from requests>=2.22.0->nlpaug) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.11/site-packages (from requests>=2.22.0->nlpaug) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.11/site-packages (from requests>=2.22.0->nlpaug) (2024.8.30)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.11/site-packages (from python-dateutil>=2.8.2->pandas>=1.2.0->nlpaug) (1.16.0)\n",
      "Requirement already satisfied: soupsieve>1.2 in /opt/conda/lib/python3.11/site-packages (from beautifulsoup4->gdown>=4.0.0->nlpaug) (2.5)\n",
      "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /opt/conda/lib/python3.11/site-packages (from requests[socks]->gdown>=4.0.0->nlpaug) (1.7.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install nlpaug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nltk in /opt/conda/lib/python3.11/site-packages (3.9.1)\n",
      "Requirement already satisfied: click in /opt/conda/lib/python3.11/site-packages (from nltk) (8.1.7)\n",
      "Requirement already satisfied: joblib in /opt/conda/lib/python3.11/site-packages (from nltk) (1.4.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /opt/conda/lib/python3.11/site-packages (from nltk) (2024.11.6)\n",
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.11/site-packages (from nltk) (4.66.4)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "5BLGs8bym3PP"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-12 15:19:56.056051: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-02-12 15:19:56.068929: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2025-02-12 15:19:56.086426: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2025-02-12 15:19:56.091687: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-02-12 15:19:56.104578: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-02-12 15:19:57.234376: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "[nltk_data] Downloading package wordnet to /home/jovyan/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /home/jovyan/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import datetime\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from tqdm import tqdm\n",
    "from transformers import BertTokenizer, BertModel, AdamW\n",
    "import spacy\n",
    "import re\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, jaccard_score, classification_report\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from torch.cuda.amp import GradScaler, autocast\n",
    "import nlpaug.augmenter.word as naw\n",
    "import nltk\n",
    "nltk.download('wordnet')\n",
    "nltk.download('averaged_perceptron_tagger')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "aug = naw.SynonymAug(aug_src='wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "RXvkPa5em3wO"
   },
   "outputs": [],
   "source": [
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "2bXdhhuym_RO"
   },
   "outputs": [],
   "source": [
    "# cd drive/MyDrive/CodaBench_Sem_Eval/val/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cd val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XWt-V5lcohq1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "# GPU/CPU Device Setup\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Load Data\n",
    "train = pd.read_csv('../public_data_test/track_a/train/eng.csv')\n",
    "val = pd.read_csv('../public_data_test/track_a/dev/eng.csv')\n",
    "test = pd.read_csv('../public_data_test/track_a/test/eng.csv')\n",
    "emotions = [\"anger\", \"fear\", \"joy\", \"sadness\", \"surprise\"]\n",
    "\n",
    "# Initialize BERT Tokenizer & Model\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "bert_model = BertModel.from_pretrained('bert-base-uncased').to(device)\n",
    "nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CQAhtzAsl-z8"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "We strongly recommend passing in an `attention_mask` since your input_ids may be padded. See https://huggingface.co/docs/transformers/troubleshooting#incorrect-output-when-padding-tokens-arent-masked.\n"
     ]
    }
   ],
   "source": [
    "# Preprocessing Function\n",
    "def pre_process(text):\n",
    "    text = re.sub(r\"[.,;:!?'\\\"“”()]\", \"\", text)  # Remove punctuation\n",
    "    encoded_input = tokenizer(text, return_tensors='pt', truncation=True, padding='max_length', max_length=128)\n",
    "    return encoded_input['input_ids'].squeeze(0).to(device)\n",
    "\n",
    "# Convert Text to BERT Embeddings\n",
    "def get_bert_embeddings(texts):\n",
    "    embeddings = []\n",
    "    for text in texts:\n",
    "        input_ids = pre_process(text).unsqueeze(0)\n",
    "        with torch.no_grad():\n",
    "            outputs = bert_model(input_ids)\n",
    "        embeddings.append(outputs.last_hidden_state[:, 0, :].cpu().numpy())  # Extract [CLS] token\n",
    "    return np.vstack(embeddings)\n",
    "\n",
    "X_train = get_bert_embeddings(train[\"text\"])\n",
    "X_val = get_bert_embeddings(val[\"text\"])\n",
    "\n",
    "# POS Feature Extraction\n",
    "def get_pos_features(texts):\n",
    "    return [[token.pos_ for token in nlp(text)] for text in texts]\n",
    "\n",
    "train_pos_tags = get_pos_features(train[\"text\"])\n",
    "val_pos_tags = get_pos_features(val[\"text\"])\n",
    "\n",
    "# Convert POS Tags to Indices\n",
    "pos_vocab = {pos: idx for idx, pos in enumerate(set(tag for tags in train_pos_tags for tag in tags))}\n",
    "train_pos_indices = [[pos_vocab[tag] for tag in tags] for tags in train_pos_tags]\n",
    "val_pos_indices = [[pos_vocab.get(tag, 0) for tag in tags] for tags in val_pos_tags]\n",
    "\n",
    "# Pad POS Sequences to Fixed Length\n",
    "max_length = max(max(len(seq) for seq in train_pos_indices), max(len(seq) for seq in val_pos_indices))\n",
    "train_pos_indices = [seq + [0] * (max_length - len(seq)) for seq in train_pos_indices]\n",
    "val_pos_indices = [seq + [0] * (max_length - len(seq)) for seq in val_pos_indices]\n",
    "\n",
    "# Convert to PyTorch Tensors\n",
    "train_pos_indices = torch.tensor(train_pos_indices, dtype=torch.long).to(device)\n",
    "val_pos_indices = torch.tensor(val_pos_indices, dtype=torch.long).to(device)\n",
    "\n",
    "# Trainable POS Embedding Layer with LSTM\n",
    "class POSEmbedding(nn.Module):\n",
    "    def __init__(self, num_pos_tags, embedding_dim):\n",
    "        super(POSEmbedding, self).__init__()\n",
    "        self.embedding = nn.Embedding(num_pos_tags, embedding_dim)\n",
    "        self.lstm = nn.LSTM(embedding_dim, embedding_dim, batch_first=True)\n",
    "\n",
    "    def forward(self, pos_indices):\n",
    "        pos_embeds = self.embedding(pos_indices)\n",
    "        lstm_out, _ = self.lstm(pos_embeds)\n",
    "        return lstm_out[:, -1, :]  # Use the last hidden state\n",
    "\n",
    "pos_embedding_layer = POSEmbedding(len(pos_vocab), embedding_dim=16).to(device)\n",
    "\n",
    "# Model Definition\n",
    "class EmotionClassifier(nn.Module):\n",
    "    def __init__(self, bert_dim=768, pos_dim=16, hidden_dim=128, output_dim=5):\n",
    "        super(EmotionClassifier, self).__init__()\n",
    "        self.fc1 = nn.Linear(bert_dim + pos_dim, hidden_dim)\n",
    "        self.fc2 = nn.Linear(hidden_dim, output_dim)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, bert_embeddings, pos_indices):\n",
    "        pos_embeds = pos_embedding_layer(pos_indices)\n",
    "        combined_features = torch.cat((bert_embeddings, pos_embeds), dim=1)\n",
    "        x = self.relu(self.fc1(combined_features))\n",
    "        return self.fc2(x)\n",
    "\n",
    "# Initialize Model\n",
    "model = EmotionClassifier().to(device)\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "optimizer = AdamW(model.parameters(), lr=2e-5)\n",
    "\n",
    "# Data Augmentation\n",
    "aug = naw.SynonymAug(aug_src='wordnet')\n",
    "train[\"text\"] = train[\"text\"].apply(lambda x: aug.augment(x))\n",
    "\n",
    "# Prepare Training Data\n",
    "y_train = torch.tensor(train[emotions].values, dtype=torch.float32).to(device)\n",
    "y_val = torch.tensor(val[emotions].values, dtype=torch.float32).to(device)\n",
    "\n",
    "train_features = torch.tensor(X_train, dtype=torch.float32).to(device)\n",
    "val_features = torch.tensor(X_val, dtype=torch.float32).to(device)\n",
    "\n",
    "dataset = TensorDataset(train_features, train_pos_indices, y_train)\n",
    "data_loader = DataLoader(dataset, batch_size=16, shuffle=True)\n",
    "\n",
    "# Training Loop with Adversarial Training\n",
    "scaler = GradScaler()\n",
    "epochs = 10\n",
    "\n",
    "for epoch in tqdm(range(epochs), desc=\"Training Loop\"):\n",
    "    model.train()\n",
    "    for features, pos_indices, labels in data_loader:\n",
    "        optimizer.zero_grad()\n",
    "        with autocast():\n",
    "            outputs = model(features, pos_indices)\n",
    "            loss = criterion(outputs, labels)\n",
    "        scaler.scale(loss).backward()\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "\n",
    "    if epoch % 1 == 0:\n",
    "        print(f\"Epoch {epoch}: Loss: {round(loss.item(), 3)}\")\n",
    "\n",
    "# Dynamic Thresholding\n",
    "def find_optimal_thresholds(y_true, y_pred_probs):\n",
    "    thresholds = {}\n",
    "    for i, emotion in enumerate(emotions):\n",
    "        best_threshold = 0.5\n",
    "        best_f1 = 0\n",
    "        for threshold in np.arange(0.1, 1.0, 0.05):\n",
    "            y_pred = (y_pred_probs[:, i] > threshold).astype(int)\n",
    "            f1 = f1_score(y_true[:, i], y_pred)\n",
    "            if f1 > best_f1:\n",
    "                best_f1 = f1\n",
    "                best_threshold = threshold\n",
    "        thresholds[emotion] = best_threshold\n",
    "    return thresholds\n",
    "\n",
    "# Generate Predictions\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    y_pred_probs = torch.sigmoid(model(val_features, val_pos_indices)).cpu().numpy()\n",
    "\n",
    "thresholds = find_optimal_thresholds(y_val.cpu().numpy(), y_pred_probs)\n",
    "y_pred = np.zeros_like(y_pred_probs)\n",
    "for i, emotion in enumerate(emotions):\n",
    "    y_pred[:, i] = (y_pred_probs[:, i] > thresholds[emotion]).astype(int)\n",
    "\n",
    "# Evaluation\n",
    "print(classification_report(y_val.cpu().numpy(), y_pred, target_names=emotions))"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "private_outputs": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
